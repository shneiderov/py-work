{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корреляционный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Термин «корреляция» (correlation) ввел в статистику английский биолог и статистик Фрэнсис Гальтон в конце XIX в. А в палеонтологии в XVIII в. известный французский ученый Жорж Кювье, специалист по ископаемым останкам животных, ввел в научный оборот так называемый закон корреляции, который он использовал для изучения связи частей и органов живых существ. С помощью закона корреляции можно было восстановить облик ископаемого животного, имея в распоряжении лишь часть его останков.\n",
    "\n",
    "Дальнейшее развитие корреляционный анализ получил в трудах Карла Пирсона (1857-1936) и Джорджа Юла (1871-1951), которые разработали и ввели в научный оборот термин «парный коэффициент корреляции», который по сей день является одним из основных инструментов, позволяющих изучать взаимосвязь нескольких признаков.\n",
    "\n",
    "Корреляционный анализ применятся тогда, когда данные наблюдений можно считать случайными и выбранными из генеральной совокупности, распределенной по нормальному (многомерному) закону."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Между величинами различают два вида зависимостей: **детерминированную** (функциональную), и **вероятностную** (стохастическую, статистическую).\n",
    "\n",
    "При детерминированной зависимости имеет место **однозначность отображения множества значений величины**, т.е. для взаимозависимых величин $x$ и $y$ существует правило соответствия $y = f(x)$. Функциональную связь называют **явной**, так как они связывают показатели, полученные вычислением по заранее известным формулам и законам. Следовательно, значение зависимой величины становится известным, как только известны значения величины, от которой она зависит.\n",
    "\n",
    "*В экономике примером функциональной связи может служить зависимость между объемом произведенной продукции и производительностью труда; объемом произведенной продукции и затратами рабочего времени; численностью работников и фондом оплаты труда и др.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, функциональной зависимостью величины $y$ от величины $x$ называют зависимость вида $y = f(x)$, где каждому допустимому значению $x$ ставится в соответствие по определенному правилу единственно возможное значение переменной $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Множественность результатов при анализе связи между величинами $x$ и $y$ объясняется прежде всего тем, что зависимая величина $y$ испытывает влияние не только фактора $x$, но и ряда других факторов, которые не учитываются при анализе. Кроме того, влияние фактора $x$ может не быть прямым, а проявляться через цепочку других факторов.\n",
    "\n",
    "Если каждому значению величины $x$ соответствует не одно, а целое множество значений величины $y$, то такая зависимость называется статистической (стохастической). Все связи, которые могут быть численно измерены, подходят под определение статистической связи. При такой связи разным значениям одной величины соответствуют разные законы распределения значений другой величины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если изменение одной из случайных величин приводит к изменению среднего значения другой случайной величины, то такую зависимость называют **корреляционной**. **Корреляционная связь** – это частный случай статистической связи.\n",
    "\n",
    "В зависимости от направления функциональные и стохастические связи могут быть **прямыми** и **обратными**. По форме (аналитическому выражению) связи могут быть **линейными** и **нелинейными** (криволинейными). По количеству факторов, действующих на величину, связи классифицируются на **простые (однофакторные)** и **многофакторные**, когда на величину оказывают воздействие два признака или более. Однофакторные, или простые, связи обычно называют **парными**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корреляционный анализ взаимосвязи количественных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При построении корреляционных моделей исходят из **условия нормальности многомерного закона распределения генеральной совокупности**. Эти условия обеспечивают линейный характер связи между изучаемыми признаками и позволяют для исследования взаимосвязи между переменными использовать **линейные коэффициенты корреляции**. На практике в качестве показателей тесноты связи рассчитывают три линейных коэффициента корреляции: **парный**, **частный** и **множественный**, каждый из которых несет свою смысловую нагрузку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парный коэффициент корреляции (коэффициент корреляции Пирсона) характеризует **степень линейной зависимости между двумя величинами на фоне действия всех остальных величин**, отобранных для анализа. Taк, например, парный коэффициент корреляции $\\rho_{1,2}$ характеризует степень линейной зависимости между величинами $x_1$, и $х_2$ на фоне влияния остальных величин $x_3$, $x_4$, ..., $x_k$.\n",
    "\n",
    "В силу своих свойств и простоты вычисления парный коэффициент корреляции $\\rho$ является одним из самых распространенных способов измерения линейной связи между случайными величинами в генеральной совокупности. Величина парного коэффициента корреляции лежит в интервале от —1 до +1. Значение $\\rho = +1$ свидетельствует о наличии функциональной зависимости между рассматриваемыми величинами. Если $\\rho = 0$, то можно сделать вывод о том, что линейная связь между переменными $x$ и $y$ отсутствует, однако это не означает, что они статистически независимы. В этом случае возможно существование иной, нелинейной формы зависимости между величинами.\n",
    "\n",
    "**Основные свойства парного коэффициента корреляции**\n",
    "- $ -1 \\le \\rho_{i,j} \\le +1$;\n",
    "- если случайные величины $x$ и $y$, статистически независимы, то $\\rho_{x,y} = 0$, а в случае нормального распределения из некоррелированности $x$ и $y$, когда $\\rho_{x,y} = 0$, следует их независимость;\n",
    "- из условия $|\\rho_{x,y}| = 1$ следует наличие функциональной линейной связи между $x$ и $y$, и наоборот, если $x$ и $y$ связаны линейной функциональной зависимостью, то $|\\rho_{x,y}| = 1$;\n",
    "- сила корреляционной связи не зависит от ее направленности и определяется по абсолютному значению коэффициента корреляции;\n",
    "- парный коэффициент корреляции является симметричной характеристикой, т.е. $\\rho_{x,y} = \\rho_{y,x}$, что непосредственно следует из определения;\n",
    "- линейные преобразования величин не влияют на величину коэффициента корреляции; если все значения величин увеличить (уменьшить) на одно и то же число или в одно и то же число раз, то величина коэффициента корреляции не изменится;\n",
    "- коэффициент корреляции не имеет размерности и, следовательно, его можно сопоставлять для разных выборок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчёт оценки коэффициента корреляции\n",
    "\n",
    "Исходная матрица "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
